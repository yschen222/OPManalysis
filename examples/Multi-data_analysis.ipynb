{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "334f6a66-32cd-419b-aaf3-4c1f011a563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ROOT] é–‹å§‹è™•ç†ï¼š01  (0/3)\n",
      "[01] 10%  (1/10)\n",
      "[01] 20%  (2/10)\n",
      "[01] 30%  (3/10)\n",
      "[01] 40%  (4/10)\n",
      "[01] 50%  (5/10)\n",
      "[01] 60%  (6/10)\n",
      "[01] 70%  (7/10)\n",
      "[01] 80%  (8/10)\n",
      "[01] 90%  (9/10)\n",
      "[01] 100%  (10/10)\n",
      "[ROOT] å®Œæˆï¼š01       (1/3)\n",
      "[ROOT] 33%  (1/3)\n",
      "[ROOT] é–‹å§‹è™•ç†ï¼š02  (1/3)\n",
      "[02] 10%  (1/10)\n",
      "[02] 20%  (2/10)\n",
      "[02] 30%  (3/10)\n",
      "[02] 40%  (4/10)\n",
      "[02] 50%  (5/10)\n",
      "[02] 60%  (6/10)\n",
      "[02] 70%  (7/10)\n",
      "[02] 80%  (8/10)\n",
      "[02] 90%  (9/10)\n",
      "[02] 100%  (10/10)\n",
      "[ROOT] å®Œæˆï¼š02       (2/3)\n",
      "[ROOT] 66%  (2/3)\n",
      "[ROOT] é–‹å§‹è™•ç†ï¼š03  (2/3)\n",
      "[03] 10%  (1/10)\n",
      "[03] 20%  (2/10)\n",
      "[03] 30%  (3/10)\n",
      "[03] 40%  (4/10)\n",
      "[03] 50%  (5/10)\n",
      "[03] 60%  (6/10)\n",
      "[03] 70%  (7/10)\n",
      "[03] 80%  (8/10)\n",
      "[03] 90%  (9/10)\n",
      "[03] 100%  (10/10)\n",
      "[ROOT] å®Œæˆï¼š03       (3/3)\n",
      "[ROOT] 100%  (3/3)\n",
      "\n",
      "================================================================================\n",
      "                                   ALL (å½™æ•´ç¸½è¡¨)                                   \n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ åŸºæœ¬è³‡è¨Šï¼š\n",
      "label                                  folder_name                                   current_mA B_range_used_nT\n",
      " 128  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\128     128     [-32.12, 32.12]\n",
      " 132  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\132     132     [-32.12, 32.12]\n",
      " 136  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\136     136     [-32.12, 32.12]\n",
      " 138  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\138     138     [-32.12, 32.12]\n",
      " 140  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\140     140     [-32.12, 32.12]\n",
      " 142  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\142     142     [-32.12, 32.12]\n",
      " 144  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\144     144     [-32.12, 32.12]\n",
      " 148  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\148     148     [-32.12, 32.12]\n",
      " 152  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\152     152     [-32.12, 32.12]\n",
      " 156  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\01\\156     156     [-32.12, 32.12]\n",
      " 128  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\128     128     [-32.12, 32.12]\n",
      " 132  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\132     132     [-32.12, 32.12]\n",
      " 136  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\136     136     [-32.12, 32.12]\n",
      " 138  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\138     138     [-32.12, 32.12]\n",
      " 140  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\140     140     [-32.12, 32.12]\n",
      " 142  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\142     142     [-32.12, 32.12]\n",
      " 144  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\144     144     [-32.12, 32.12]\n",
      " 148  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\148     148     [-32.12, 32.12]\n",
      " 152  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\152     152     [-32.12, 32.12]\n",
      " 156  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\02\\156     156     [-32.12, 32.12]\n",
      " 128  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\128     128     [-32.12, 32.12]\n",
      " 132  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\132     132     [-32.12, 32.12]\n",
      " 136  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\136     136     [-32.12, 32.12]\n",
      " 138  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\138     138     [-32.12, 32.12]\n",
      " 140  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\140     140     [-32.12, 32.12]\n",
      " 142  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\142     142     [-32.12, 32.12]\n",
      " 144  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\144     144     [-32.12, 32.12]\n",
      " 148  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\148     148     [-32.12, 32.12]\n",
      " 152  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\152     152     [-32.12, 32.12]\n",
      " 156  C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\03\\156     156     [-32.12, 32.12]\n",
      "\n",
      "ğŸ“Š æ¸¬é‡çµæœï¼š\n",
      " slope_mV_per_nT  slope_R2  noise_rms_uV_per_rtHz  sensitivity_pT_per_rtHz  lorentz_FWHM_nT  lorentz_R2  gaussian_FWHM_nT  gaussian_R2  voigt_FWHM_nT  voigt_R2\n",
      "     0.468         0.974            11.3                    24.1                 22.9          0.999             22          0.991          22.3        0.996  \n",
      "     0.855         0.995            9.98                    11.7                 18.9          0.999           19.2          0.994            19        0.998  \n",
      "      1.34         0.998            9.86                    7.36                 19.1          0.998           19.3          0.995          19.3        0.998  \n",
      "      1.41         0.999            11.7                    8.26                 15.5          0.994           16.5          0.997          16.2        0.997  \n",
      "      1.33         0.999            8.48                    6.35                 12.3          0.989           13.6          0.998          13.1        0.996  \n",
      "      1.19         0.999            6.95                    5.85                 11.2          0.986           12.6          0.999          12.1        0.994  \n",
      "      1.31         0.999            7.64                    5.83                 13.5           0.99           14.8          0.998          14.4        0.996  \n",
      "      1.22         0.999            7.08                     5.8                 14.1          0.991           15.3          0.998          14.9        0.996  \n",
      "      1.21         0.998            5.96                    4.91                 14.7          0.994           15.9          0.996          15.4        0.997  \n",
      "      1.38         0.998            7.13                    5.19                 21.8          0.999           21.2          0.993          21.5        0.997  \n",
      "     0.403         0.974            9.66                    23.9                 21.9          0.999           21.4          0.991          21.5        0.996  \n",
      "     0.821         0.995            10.3                    12.6                 18.6          0.999             19          0.994          18.8        0.998  \n",
      "      1.36         0.998            12.4                    9.11                 16.5          0.996           17.4          0.996            17        0.998  \n",
      "      1.39         0.999            10.7                    7.74                 14.9          0.993             16          0.997          15.6        0.998  \n",
      "      1.26         0.999            7.16                    5.69                 11.9          0.988           13.3          0.998          12.8        0.995  \n",
      "      1.25         0.999            7.84                    6.27                   12          0.988           13.4          0.998          12.9        0.995  \n",
      "      1.18         0.999            7.49                    6.37                 11.1           0.98           12.5          0.997          12.1        0.989  \n",
      "      1.09         0.999            4.88                    4.48                 11.3          0.987           12.8          0.998          12.2        0.995  \n",
      "      1.26         0.999            6.04                    4.81                 15.4          0.995           16.5          0.996            16        0.998  \n",
      "      1.38         0.998            7.02                     5.1                   21          0.999           20.7          0.992          20.8        0.997  \n",
      "     0.469         0.972            8.72                    18.6                 25.6          0.999           23.7          0.991          24.4        0.995  \n",
      "     0.889         0.994            9.83                    11.1                 22.2          0.999           21.5          0.993          21.8        0.997  \n",
      "       1.4         0.998            9.48                    6.79                 19.9          0.998           19.9          0.995          19.9        0.998  \n",
      "      1.41         0.998            7.89                    5.58                   17          0.996           17.8          0.996          17.5        0.998  \n",
      "       1.3         0.999            8.02                    6.16                 13.2           0.99           14.5          0.998            14        0.996  \n",
      "      1.35         0.999            6.39                    4.73                 14.7          0.991           15.9          0.998          15.5        0.997  \n",
      "      1.29         0.999            5.77                    4.46                 14.3          0.991           15.5          0.998          15.1        0.996  \n",
      "      1.18         0.999            4.86                    4.12                 13.6           0.99           14.9          0.998          14.5        0.996  \n",
      "      1.35         0.998            6.46                    4.78                 17.6          0.977             18          0.974          17.8        0.978  \n",
      "       1.4         0.998            6.79                    4.86                 21.3          0.999           20.9          0.992          21.1        0.997  \n",
      "================================================================================\n",
      "å…± 30 ç­†è³‡æ–™\n",
      "================================================================================\n",
      "[OK] å·²è¼¸å‡º CSVï¼šC:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·.csv\n",
      "[OK] å·²è¼¸å‡º XLSXï¼šC:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ====== notifier.pyï¼ˆç›´æ¥è²¼åˆ°ä½ çš„è…³æœ¬é ‚ç«¯å°±å¥½ï¼‰======\n",
    "import os, sys, time, platform, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def _beep_fallback(times=2, freq=1000, dur_ms=500):\n",
    "    \"\"\"ç›¡åŠ›å—¶ä¸€ä¸‹ï¼ˆWindows winsound / çµ‚ç«¯ bell / macOS sayï¼‰ã€‚\"\"\"\n",
    "    try:\n",
    "        if platform.system() == \"Windows\":\n",
    "            import winsound\n",
    "            for _ in range(times):\n",
    "                winsound.Beep(freq, dur_ms)\n",
    "                time.sleep(0.15)\n",
    "            return True\n",
    "        elif platform.system() == \"Darwin\":\n",
    "            # macOSï¼šç³»çµ±èªéŸ³ or terminal bell\n",
    "            os.system('say \"job finished\"')  # è‹¥ä½ ä¸æƒ³è¬›è©±å¯æ”¹æˆ print('\\a')\n",
    "            return True\n",
    "        else:\n",
    "            # Linux/å…¶ä»–ï¼šçµ‚ç«¯ bell\n",
    "            sys.stdout.write('\\a' * times); sys.stdout.flush()\n",
    "            return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def _toast_windows(title, msg, duration=5):\n",
    "    \"\"\"Windows Toastï¼ˆéœ€è¦ pip install win10toastï¼‰ã€‚\"\"\"\n",
    "    try:\n",
    "        from win10toast import ToastNotifier\n",
    "        ToastNotifier().show_toast(title, msg, duration=duration, threaded=True)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _toast_plyer(title, msg):\n",
    "    \"\"\"é€šç”¨æ¡Œé¢é€šçŸ¥ï¼ˆpip install plyerï¼‰ã€‚\"\"\"\n",
    "    try:\n",
    "        from plyer import notification\n",
    "        notification.notify(title=title, message=msg, timeout=5)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _toast_linux(title, msg):\n",
    "    \"\"\"Linux notify-sendï¼ˆç³»çµ±é€šå¸¸è‡ªå¸¶ï¼‰ã€‚\"\"\"\n",
    "    try:\n",
    "        subprocess.Popen([\"notify-send\", title, msg])\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _popup_windows(title, msg):\n",
    "    \"\"\"Windows åŸç”Ÿå½ˆçª—ï¼ˆä¸éœ€å®‰è£å¥—ä»¶ï¼‰ã€‚\"\"\"\n",
    "    try:\n",
    "        import ctypes\n",
    "        ctypes.windll.user32.MessageBoxW(0, msg, title, 0x40)  # MB_ICONINFORMATION\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def notify_done(msg=\"ä»»å‹™å®Œæˆ âœ…\", title=\"OPM æ‰¹æ¬¡ä»»å‹™\"):\n",
    "    \"\"\"\n",
    "    å®Œæˆæ™‚å«ä½ ï¼šå„ªå…ˆæ¡Œé¢é€šçŸ¥â†’å½ˆçª—â†’å—¶è²â†’çµ‚ç«¯æç¤ºã€‚\n",
    "    æ”¾åœ¨ä»»å‹™çµå°¾ï¼Œæˆ– except/finally ä¸­ã€‚\n",
    "    \"\"\"\n",
    "    ok = False\n",
    "    system = platform.system()\n",
    "\n",
    "    # æ¡Œé¢é€šçŸ¥ï¼ˆå„ªå…ˆï¼‰\n",
    "    if system == \"Windows\":\n",
    "        ok = _toast_windows(title, msg) or _toast_plyer(title, msg)\n",
    "    elif system == \"Darwin\":\n",
    "        # macOS: å„ªå…ˆ plyerï¼Œå…¶æ¬¡ AppleScript\n",
    "        ok = _toast_plyer(title, msg)\n",
    "        if not ok:\n",
    "            try:\n",
    "                script = f'display notification \"{msg}\" with title \"{title}\"'\n",
    "                subprocess.Popen([\"osascript\", \"-e\", script])\n",
    "                ok = True\n",
    "            except Exception:\n",
    "                ok = False\n",
    "    else:\n",
    "        # Linux\n",
    "        ok = _toast_plyer(title, msg) or _toast_linux(title, msg)\n",
    "\n",
    "    # é€€è€Œæ±‚å…¶æ¬¡ï¼šWindows åŸç”Ÿå½ˆçª—\n",
    "    if not ok and system == \"Windows\":\n",
    "        ok = _popup_windows(title, msg)\n",
    "\n",
    "    # å†é€€ï¼šå—¶è²/èªéŸ³\n",
    "    if not ok:\n",
    "        ok = _beep_fallback(times=2)\n",
    "\n",
    "    # æœ€å¾Œä¿åº•è¼¸å‡º\n",
    "    if not ok:\n",
    "        print(f\"\\n=== {title} ===\\n{msg}\\n\")\n",
    "\n",
    "def run_with_notify(func, *args, title=\"OPM æ‰¹æ¬¡ä»»å‹™\", **kwargs):\n",
    "    \"\"\"\n",
    "    ç”¨æ³•ï¼šrun_with_notify(process_root, root_dir)\n",
    "    æˆåŠŸèˆ‡å¤±æ•—éƒ½æœƒé€šçŸ¥ï¼›å¤±æ•—æœƒæŠŠä¾‹å¤–è¨Šæ¯ä¹Ÿå¸¶å‡ºä¾†ã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = func(*args, **kwargs)\n",
    "        notify_done(\"å·²åŸ·è¡Œå®Œæˆ âœ…\", title=title)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        notify_done(f\"åŸ·è¡Œå¤±æ•— âŒï¼š{e}\", title=title)\n",
    "        raise\n",
    "\n",
    "# batch_opm_summary.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json, re\n",
    "# ä¾è³´ä½ çš„å·¥å…·ï¼šè«‹ç¢ºèª opmtool åœ¨å¯åŒ¯å…¥çš„è·¯å¾‘\n",
    "from opmtool import (\n",
    "    dispersion_lorentz_fit, voigt_fit, lorentz_fit, gauss_fit,\n",
    "    one_cycle_cut, noise_psd, noise_psd_lowband\n",
    ")\n",
    "import warnings\n",
    "# å¾Œç«¯ç”¨ Aggï¼Œé¿å…å½ˆè¦–çª— & ç´…å­—\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# ğŸ”§ å…¨åŸŸè¨­å®š\n",
    "# =========================\n",
    "# ---- è¼¸å‡ºæ§åˆ¶ ----\n",
    "XLSX_SHEET_MODE = \"all_only\"   # \"all_only\" | \"per_session\"\n",
    "PRINT_SUMMARY_TO_STDOUT = True # è·‘å®Œç›´æ¥æŠŠ ALL ç¸½è¡¨å°åœ¨çµ‚ç«¯æ©Ÿ\n",
    "STDOUT_MAX_ROWS = 200          # é¿å…è¶…é•·æ´—ç‰ˆï¼›æƒ³å…¨å°å¯è¨­ None\n",
    "\n",
    "# ---- åœ–åƒè¼¸å‡ºè¨­å®š ----\n",
    "PLOT_ENABLED = True          # â† é–‹/é—œ ä½œåœ–å­˜æª”\n",
    "PLOT_DPI     = 140\n",
    "PLOT_FMT     = \"png\"\n",
    "PLOT_STYLE   = \"default\"     # ä½ å–œæ­¡çš„ matplotlib styleï¼Œæˆ– \"seaborn-v0_8\"\n",
    "PLOT_MAXPTS  = 4000          # ç•«é»å¤ªå¤šæœƒå¾ˆæ…¢ï¼Œè¶…éå°±ç­‰è·æŠ½æ¨£ç¹ªé»\n",
    "plt.style.use(PLOT_STYLE)\n",
    "# ===== å¯¦é©—æ¨¡å¼(æœ‰é è¨­è³‡æ–™å¤¾åç¨±å‰‡æœƒè‡ªå‹•å°‹æ‰¾) =====\n",
    "# \"current\" = å›ºå®šå…‰å¼·æ”¹æ³¢é•·ï¼ˆè³‡æ–™å¤¾ 128, 132 è¡¨ã€Œé›·å°„é›»æµåˆ»åº¦ã€ï¼‰\n",
    "# \"power\"   = å›ºå®šé »ç‡æƒå…‰å¼·ï¼ˆè³‡æ–™å¤¾ 160, 180 è¡¨ã€ŒAOM/è¡°æ¸›å™¨æ§åˆ¶é›»å£“ã€ç­‰ï¼‰\n",
    "EXPERIMENT_MODE = \"current\"   # or \"current\"\n",
    "\n",
    "# è‹¥æ˜¯ \"current\" æ¨¡å¼ï¼Œè¦æŠŠè³‡æ–™å¤¾æ•¸å­—åŠ ä¸Šæ ¡æ­£ï¼ˆä¾‹å¦‚ 128 -> 128.4 mAï¼‰\n",
    "CURRENT_OFFSET_MA = 0.4\n",
    "\n",
    "# è‹¥æ˜¯ \"power\" æ¨¡å¼ï¼šæŠŠè³‡æ–™å¤¾æ•¸å­—è¦–ç‚ºæ§åˆ¶é›»å£“ï¼ˆå–®ä½è‡ªè¨‚ï¼‰\n",
    "POWER_UNIT   = \"mV\"        # ä½ å¯¦éš›çš„å–®ä½ï¼ˆmV or Vï¼‰\n",
    "POWER_SCALE  = 1.0         # éœ€è¦å°±æ›ç®— (é¡¯ç¤ºå€¼ = åŸå€¼*POWER_SCALE + POWER_OFFSET)\n",
    "POWER_OFFSET = 0.0\n",
    "\n",
    "# æƒå ´åˆ‡åŠã€B æ˜ å°„\n",
    "B_RANGE_NT     = (-32.12, 32.12)#å¦‚æœæ²’æœ‰å¯¦é©—è¨˜éŒ„\n",
    "LINE_SEGMENT   = 'half'       # 'half' | 'full'\n",
    "LINE_DIRECTION = 'auto'       # 'auto' | 'rising' | 'falling'\n",
    "\n",
    "# æ–œç‡æ“¬åˆï¼šä¸­å¿ƒè‡ªå‹•ä¼°ï¼ˆé›¶äº¤è¶Šï¼‰ï¼Œè¦–çª—å¯¬åº¦ = å…¨åŸŸ B ç¯„åœçš„ç™¾åˆ†æ¯”ï¼ˆåŠå¯¬ï¼‰\n",
    "DISP_CENTER   = 0.0           # åƒ…åœ¨ fallback æ™‚ç•¶é è¨­\n",
    "WIDTHRATIO    = 10.0           # 5% â†’ åŠå¯¬ = 0.05 * (max(B)-min(B))\n",
    "DISP_P0_AMPL = 0.01\n",
    "\n",
    "# é›œè¨Šè¨ˆç®—\n",
    "NOISE_MODE                = \"lowband\"  # \"lowband\" | \"plain\"\n",
    "NOISE_BAND                = (3.0, 80.0)\n",
    "NOISE_LOCK_DF_HZ          = 0.20\n",
    "NOISE_DETREND             = \"linear\"   # \"linear\" | \"constant\" | None\n",
    "NOISE_ENABLE_PREPROCESS   = True\n",
    "NOISE_WINDOW              = \"hann\"\n",
    "NOISE_AVERAGE             = \"median\"\n",
    "\n",
    "# æª”æ¡ˆé¸å–\n",
    "SCAN_CSV_GLOB   = \"*.csv\"\n",
    "NOISE_SUBDIR    = \"noise\"\n",
    "# å›åˆè³‡æ–™å¤¾åç¨±æ¨£å¼ï¼ˆe.g. '01', '02', '03'â€¦ï¼‰\n",
    "SESSION_NAME_PATTERN = r\"^\\d{2,}$\"     # å…©ç¢¼ä»¥ä¸Šç´”æ•¸å­—å°±è¦–ç‚ºå›åˆè³‡æ–™å¤¾\n",
    "CURRENT_OFFSET_MA    = 0.4             # ä½ çš„ã€Œ128 â†’ 128.4ã€é€™ç¨®å¸¸æ•¸åç§»\n",
    "EXCEL_PER_SESSION    = True            # True â†’ å¤šåˆ†é  .xlsxï¼›False â†’ åƒ… CSV\n",
    "\n",
    "\n",
    "# CSV æ¬„ä½é¸æ“‡ï¼ˆå¤§å°å¯«ä¸æ•æ„Ÿï¼‰\n",
    "# å¯é¸ï¼š \"slope\", \"sloper2\", \"noisepsd\", \"sensitivity\",\n",
    "#       \"lorentzfwhm\", \"gaussianfwhm\", \"voigtfwhm\", \"voigtgamma\", \"voigtsigma\"\n",
    "SELECT_METRICS = [\n",
    "    \"slope\", \"sloper2\", \"noisepsd\", \"sensitivity\",\n",
    "    \"lorentzfwhm\",         \n",
    "    \"gaussianfwhm\",       \n",
    "    \"voigtfwhm\"\n",
    "]\n",
    "\n",
    "# å‹•æ…‹æ¬„åï¼ˆå¯«åˆ° CSVï¼‰\n",
    "if EXPERIMENT_MODE.lower() == \"current\":\n",
    "    SWEEP_COL_NAME = \"current_mA\"\n",
    "elif EXPERIMENT_MODE.lower() == \"power\":\n",
    "    SWEEP_COL_NAME = f\"power_ctrl_{POWER_UNIT}\"\n",
    "else:\n",
    "    raise ValueError(\"EXPERIMENT_MODE must be 'current' or 'power'\")\n",
    "    \n",
    "# æ¬„ä½å°æ‡‰ï¼ˆè¼¸å‡ºåç¨±ï¼‰\n",
    "ALWAYS_COLUMNS = [\"label\", \"folder_name\", SWEEP_COL_NAME, \"B_range_used_nT\"]\n",
    "_METRIC_COLNAMES = {\n",
    "    \"slope\":        \"slope_mV_per_nT\",\n",
    "    \"sloper2\":      \"slope_R2\",\n",
    "    \"noisepsd\":     \"noise_rms_uV_per_rtHz\",\n",
    "    \"sensitivity\":  \"sensitivity_pT_per_rtHz\",\n",
    "    \"lorentzfwhm\":  \"lorentz_FWHM_nT\",\n",
    "    \"lorentzr2\":    \"lorentz_R2\",\n",
    "    \"gaussianfwhm\": \"gaussian_FWHM_nT\",\n",
    "    \"gaussianr2\":   \"gaussian_R2\",\n",
    "    \"voigtfwhm\":    \"voigt_FWHM_nT\",\n",
    "    \"voigtgamma\":   \"voigt_gamma_nT\",\n",
    "    \"voigtsigma\":   \"voigt_sigma_nT\",\n",
    "    \"voigtr2\":      \"voigt_R2\", \n",
    "}\n",
    "\n",
    "# æ¬„ä½ä½ç½®å°æ‡‰ï¼ˆè®€æª”ï¼‰\n",
    "SCAN_USE_POSITION  = True\n",
    "NOISE_USE_POSITION = True\n",
    "SCAN_POS_MAP  = { \"time\": 0, \"Ab\": 1, \"demod\": 2, \"tri\": 3 }\n",
    "NOISE_POS_MAP = { \"time\": 0, \"Ab\": 1, \"demod\": 2 }\n",
    "USER_SCAN_COLNAMES  = { \"time\": \"time\", \"Ab\": \"Ab\", \"demod\": \"demod\", \"tri\": \"tri\" }\n",
    "USER_NOISE_COLNAMES = { \"time\": \"time\", \"Ab\": \"Ab\", \"demod\": \"demod\" }\n",
    "\n",
    "# é¸å–®é©—è­‰ + å°å·¥å…·\n",
    "_SELECT = {s.lower() for s in SELECT_METRICS}\n",
    "for s in _SELECT:\n",
    "    if s not in _METRIC_COLNAMES:\n",
    "        raise ValueError(f\"æœªçŸ¥çš„æŒ‡æ¨™åç¨±: {s}\")\n",
    "def _want(name: str) -> bool:\n",
    "    return name.lower() in _SELECT\n",
    "\n",
    "def _extract_sweep_value(label: str) -> float:\n",
    "    \"\"\"ä¾ EXPERIMENT_MODE å¾è³‡æ–™å¤¾åæŠ½å‡º sweep è®Šæ•¸ï¼ˆé›»æµæˆ–å…‰å¼·æ§åˆ¶é›»å£“ï¼‰\"\"\"\n",
    "    val = _extract_numeric_from_label(label)  # å…ˆæŠ“åˆ°è³‡æ–™å¤¾ä¸­çš„æ•¸å­—\n",
    "    if val is None:\n",
    "        return np.nan\n",
    "    mode = EXPERIMENT_MODE.lower()\n",
    "    if mode == \"current\":\n",
    "        return float(val) + float(CURRENT_OFFSET_MA)\n",
    "    elif mode == \"power\":\n",
    "        return float(val) * float(POWER_SCALE) + float(POWER_OFFSET)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def _plot_and_save_dispersion(sub_dir, B, demod, yfit, slope, r2, lin_range=None, ctr=None, offset=None):\n",
    "    try:\n",
    "        B = np.asarray(B); demod = np.asarray(demod); yfit = np.asarray(yfit)\n",
    "    \n",
    "        plt.figure(figsize=(6.0,4.0))\n",
    "        plt.plot(B, demod, '.', ms=2, color='k', label='Demod (window)')\n",
    "        if np.all(np.isfinite(yfit)) and len(yfit)==len(B):\n",
    "            plt.plot(B, yfit, '-', lw=2, color='r', label='Dispersion fit')\n",
    "    \n",
    "        # ç·šæ€§ç¯„åœé™°å½± + å°è¨Šè™Ÿç·šæ€§è¿‘ä¼¼\n",
    "        if lin_range and ctr is not None and offset is not None and np.all(np.isfinite(lin_range)):\n",
    "            lo, hi = lin_range\n",
    "            if lo < hi:\n",
    "                plt.axvspan(lo, hi, color='tab:green', alpha=0.15, label='Linear range')\n",
    "                Bb = np.linspace(lo, hi, 200)\n",
    "                yl = offset + slope*(Bb - ctr)\n",
    "                plt.plot(Bb, yl, 'g--', lw=1.8, label='Small-signal approx')\n",
    "    \n",
    "        plt.title(f\"Dispersion fit  (RÂ²={r2:.4f}, slope={slope*1e3:.3g} mV/nT)\")\n",
    "        plt.xlabel(\"Magnetic Field (nT)\")\n",
    "        plt.ylabel(\"Demodulated Signal (V)\")\n",
    "        plt.legend(loc='best', fontsize=9)\n",
    "        plt.tight_layout()\n",
    "    \n",
    "        out_png = Path(sub_dir) / \"fit_dispersion.png\"\n",
    "        plt.savefig(out_png, dpi=180)\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] ç¹ªåœ–å¤±æ•—ï¼ˆdispersionï¼‰ï¼š{sub_dir.name}: {e}\")\n",
    "\n",
    "def _plot_and_save_lineshapes(sub_dir: Path, B, Ab,  # data\n",
    "                              want_lor, lf,          # dict æˆ– None\n",
    "                              want_gau, gf,\n",
    "                              want_voi, vf):\n",
    "    try:\n",
    "        x = np.asarray(B); y = np.asarray(Ab)\n",
    "        if len(x) > PLOT_MAXPTS:\n",
    "            idx = np.linspace(0, len(x)-1, PLOT_MAXPTS).astype(int)\n",
    "            x, y = x[idx], y[idx]\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        ax.plot(x, y, \".\", ms=2, alpha=0.5, label=\"data\")\n",
    "\n",
    "        xx = np.linspace(np.nanmin(B), np.nanmax(B), 1200)\n",
    "        if want_lor and lf:\n",
    "            # f(B) = a/(1+(b*(B-center))^2)+c\n",
    "            p = lf.get(\"Params\", {})\n",
    "            a, b, c0, ctr = p.get(\"amplitude\"), p.get(\"b\"), p.get(\"offset\"), p.get(\"center\")\n",
    "            if all(v is not None for v in (a,b,c0,ctr)):\n",
    "                yy = a/(1.0+(b*(xx-ctr))**2)+c0\n",
    "                ax.plot(xx, yy, \"--\", lw=2, label=f\"Lorentz (RÂ²={_first_scalar(lf.get('R2')):.4f})\")\n",
    "\n",
    "        if want_gau and gf:\n",
    "            # GaussianModel: amplitude, center, sigma, offset\n",
    "            p = gf.get(\"Params\", {})\n",
    "            A, mu, sig, c0 = p.get(\"amplitude\"), p.get(\"center\"), p.get(\"sigma\"), p.get(\"offset\")\n",
    "            if all(v is not None for v in (A,mu,sig,c0)):\n",
    "                yy = (A/(np.sqrt(2*np.pi)*sig))*np.exp(-0.5*((xx-mu)/sig)**2) + c0\n",
    "                ax.plot(xx, yy, \"--\", lw=2, label=f\"Gaussian (RÂ²={_first_scalar(gf.get('R2')):.4f})\")\n",
    "\n",
    "        if want_voi and vf:\n",
    "            p = vf.get(\"Params\", {})\n",
    "            A, mu, sig, gam, c0 = p.get(\"amplitude\"), p.get(\"center\"), p.get(\"sigma\"), p.get(\"gamma\"), p.get(\"offset\")\n",
    "            if all(v is not None for v in (A,mu,sig,gam,c0)):\n",
    "                # ç”¨ area-normalized Voigt å†ä¹˜ä¸Šé¢ç© Aï¼ŒåŠ ä¸Š offset\n",
    "                from scipy.special import wofz\n",
    "                def voigt_area(xx, sigma, gamma):\n",
    "                    z = (xx + 1j*gamma) / (sigma*np.sqrt(2))\n",
    "                    return np.real(wofz(z)) / (sigma*np.sqrt(2*np.pi))\n",
    "                yy = A*voigt_area(xx-mu, max(1e-12,sig), max(1e-12,gam)) + c0\n",
    "                ax.plot(xx, yy, \"--\", lw=2, label=f\"Voigt (RÂ²={_first_scalar(vf.get('R2')):.4f})\")\n",
    "\n",
    "        ax.set_xlabel(\"B (nT)\"); ax.set_ylabel(\"Absorption (V)\")\n",
    "        ax.set_title(\"Lineshape fits\")\n",
    "        ax.legend(loc=1)\n",
    "        out = sub_dir / f\"fit_lineshape.{PLOT_FMT}\"\n",
    "        fig.tight_layout(); fig.savefig(out, dpi=PLOT_DPI); plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] ç¹ªåœ–å¤±æ•—ï¼ˆlineshapeï¼‰ï¼š{sub_dir.name}: {e}\")\n",
    "\n",
    "def _plot_and_save_psd(noise_dir: Path, noise_df_std: pd.DataFrame):\n",
    "    try:\n",
    "        if not noise_dir.exists():\n",
    "            noise_dir.mkdir(parents=True, exist_ok=True)\n",
    "        # ç›´æ¥é‡ç®—ä¸€æ¬¡æ‹¿é »è­œé»ä¾†ç•«\n",
    "        if NOISE_MODE == \"lowband\":\n",
    "            pts, asd_mean, fs_used, info = noise_psd_lowband(\n",
    "                noise_df_std,\n",
    "                band=NOISE_BAND,\n",
    "                window=NOISE_WINDOW,\n",
    "                average=NOISE_AVERAGE,\n",
    "                min_freq_resolution=NOISE_LOCK_DF_HZ,\n",
    "                force_long_segments=False,\n",
    "                detrend=NOISE_DETREND,\n",
    "                snap_to_power_of_2=False,\n",
    "                enable_auto_preprocess=NOISE_ENABLE_PREPROCESS\n",
    "            )\n",
    "        else:\n",
    "            pts, asd_mean, fs_used, info = noise_psd(\n",
    "                noise_df_std,\n",
    "                band=NOISE_BAND,\n",
    "                window=NOISE_WINDOW,\n",
    "                average=NOISE_AVERAGE,\n",
    "                min_freq_resolution=NOISE_LOCK_DF_HZ,\n",
    "                force_long_segments=False,\n",
    "                detrend=NOISE_DETREND,\n",
    "                snap_to_power_of_2=False\n",
    "            )\n",
    "        f, Pxx = np.asarray(pts[:,0]), np.asarray(pts[:,1])\n",
    "        asd = np.sqrt(np.maximum(Pxx, 0))\n",
    "        fig, ax = plt.subplots(figsize=(6,4))\n",
    "        ax.semilogy(f, asd, \"-\", lw=1.5, label=\"ASD (V/âˆšHz)\")\n",
    "        f1, f2 = NOISE_BAND\n",
    "        ax.axvspan(f1, f2, alpha=0.15, label=f\"band {f1:g}â€“{f2:g} Hz\")\n",
    "        ax.set_xlabel(\"Frequency (Hz)\")\n",
    "        ax.set_ylabel(\"ASD (V/âˆšHz)\")\n",
    "        ax.set_title(f\"Noise PSD (mean={asd_mean*1e6:.3g} Î¼V/âˆšHz)\")\n",
    "        ax.legend(loc=\"best\")\n",
    "        out = noise_dir / f\"noise_psd.{PLOT_FMT}\"\n",
    "        fig.tight_layout(); fig.savefig(out, dpi=PLOT_DPI); plt.close(fig)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] ç¹ªåœ–å¤±æ•—ï¼ˆPSDï¼‰ï¼š{noise_dir.name}: {e}\")\n",
    "\n",
    "# ä»»ä½•ã€Œé¸äº†æ“¬åˆåƒæ•¸ã€â†’ å¼·åˆ¶æŠŠå°æ‡‰ RÂ² ä¸€èµ·è¼¸å‡º\n",
    "def _force_include_r2_columns(selected: set[str]) -> set[str]:\n",
    "    sel = set(selected)\n",
    "    # slopeï¼šè‹¥é¸äº† slope å°±è‡ªå‹•åŠ  sloper2ï¼ˆä½ çš„è¦å‰‡ 3ï¼‰\n",
    "    if \"slope\" in sel:\n",
    "        sel.add(\"sloper2\")\n",
    "    # Voigtï¼šåªè¦æœ‰ voigt_* å°±åŠ  voigtR2\n",
    "    if {\"voigtfwhm\",\"voigtgamma\",\"voigtsigma\"} & sel:\n",
    "        sel.add(\"voigtr2\")\n",
    "    # Lorentzï¼šè‹¥é¸ lorentzFWHM å°±åŠ  lorentzR2\n",
    "    if \"lorentzfwhm\" in sel:\n",
    "        sel.add(\"lorentzr2\")\n",
    "    # Gaussianï¼šè‹¥é¸ gaussianFWHM å°±åŠ  gaussianR2\n",
    "    if \"gaussianfwhm\" in sel:\n",
    "        sel.add(\"gaussianr2\")\n",
    "    return sel\n",
    "\n",
    "_SELECT = _force_include_r2_columns(_SELECT)\n",
    "\n",
    "def _first_scalar(x, default=np.nan):\n",
    "    \"\"\"æŠŠ 0-d/1-d çš„ numpy/pandas/ç´”æ•¸å­—ï¼Œç©©å®šè½‰æˆ floatï¼›å…¶ä»–å› defaultã€‚\"\"\"\n",
    "    try:\n",
    "        if x is None:\n",
    "            return default\n",
    "        if hasattr(x, \"values\"):                  # pandas objects\n",
    "            arr = np.asarray(x.values, dtype=float)\n",
    "            return float(arr.ravel()[0])\n",
    "        if isinstance(x, (list, tuple)):          # Python list/tuple\n",
    "            return float(np.asarray(x, dtype=float).ravel()[0])\n",
    "        arr = np.asarray(x)\n",
    "        if arr.ndim >= 1:                         # numpy array\n",
    "            return float(arr.ravel()[0])\n",
    "        return float(arr)                         # 0-d numpy scalar or float\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "\n",
    "def _load_experiment_rules(root_dir: Path):\n",
    "    \"\"\"\n",
    "    å¾ root_dir/å¯¦é©—è¨˜éŒ„.txt è®€è¦å‰‡ã€‚\n",
    "    æ”¯æ´ç¯„ä¾‹è¡Œï¼š\n",
    "      160~300çš„æƒç£ç¯„åœæ˜¯+/-32.12 nT(22 mVpp)ï¼Œ200 mHz\n",
    "      350~400çš„æƒç£ç¯„åœæ˜¯Â±64.24 nT(44 mVpp)ï¼Œ100 mHz\n",
    "      500~550çš„æƒç£ç¯„åœæ˜¯+/-96.36 nT(66 mVpp)ï¼Œ70 mHz\n",
    "    å›å‚³ list[dict]: [{'lo':160,'hi':300,'Bpm':32.12,'mVpp':22,'fmHz':200}, ...]\n",
    "    \"\"\"\n",
    "    p = root_dir / \"å¯¦é©—è¨˜éŒ„.txt\"\n",
    "    if not p.exists():\n",
    "        return []\n",
    "\n",
    "    txt = p.read_text(encoding=\"utf-8-sig\")\n",
    "    rules = []\n",
    "    # å…è¨±ã€ŒÂ±ã€æˆ–ã€Œ+/-ã€ï¼Œå…è¨±ä¸­æ–‡/è‹±æ–‡é€—è™Ÿï¼Œå…è¨±ç©ºç™½\n",
    "    pattern = re.compile(\n",
    "        r\"\"\"\n",
    "        (?P<lo>\\d+(?:\\.\\d+)?)\\s*~\\s*(?P<hi>\\d+(?:\\.\\d+)?)       # 160~300\n",
    "        .*?æƒç£ç¯„åœ.*?                                          # ä»»æ„å­—ç›´åˆ°ã€Œæƒç£ç¯„åœã€\n",
    "        (?:\\+/-|Â±)\\s*(?P<Bpm>\\d+(?:\\.\\d+)?)\\s*nT                # Â±32.12 nT\n",
    "        \\s*\\(\\s*(?P<mVpp>\\d+(?:\\.\\d+)?)\\s*mVpp\\s*\\)            # (22 mVpp)\n",
    "        [ï¼Œ,]\\s*(?P<fmHz>\\d+(?:\\.\\d+)?)\\s*mHz                   # ï¼Œ200 mHz\n",
    "        \"\"\", re.VERBOSE | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    for line in txt.splitlines():\n",
    "        m = pattern.search(line)\n",
    "        if not m:\n",
    "            continue\n",
    "        lo  = float(m.group(\"lo\"))\n",
    "        hi  = float(m.group(\"hi\"))\n",
    "        Bpm = float(m.group(\"Bpm\"))      # æ­£åŠå¹…ï¼ˆÂ±Bï¼‰\n",
    "        mVpp= float(m.group(\"mVpp\"))\n",
    "        fmHz= float(m.group(\"fmHz\"))\n",
    "        # æ¸…ç† lo>hi çš„å¥‡æ€ªå¯«æ³•\n",
    "        lo, hi = (lo, hi) if lo <= hi else (hi, lo)\n",
    "        rules.append(dict(lo=lo, hi=hi, Bpm=Bpm, mVpp=mVpp, fmHz=fmHz))\n",
    "    return rules\n",
    "\n",
    "_num_re = re.compile(r\"([-+]?\\d+(?:\\.\\d+)?)\")\n",
    "\n",
    "def _extract_numeric_from_label(label: str) -> float | None:\n",
    "    m = _num_re.search(label)\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "def _choose_rule_for_label(rules: list, label: str):\n",
    "    \"\"\"\n",
    "    ä¾è³‡æ–™å¤¾åå…§æ•¸å­—è½åœ¨å“ªå€‹å€é–“ä¾†é¸è¦å‰‡ï¼›å¤šé‡å‘½ä¸­å–æœ€çª„å€é–“ã€‚\n",
    "    å›å‚³ (B_range, meta) æˆ– (None, None)\n",
    "    \"\"\"\n",
    "    val = _extract_numeric_from_label(label)\n",
    "    if val is None or not rules:\n",
    "        return None, None\n",
    "    # æ‰€æœ‰å‘½ä¸­çš„è¦å‰‡\n",
    "    hits = [r for r in rules if r[\"lo\"] <= val <= r[\"hi\"]]\n",
    "    if not hits:\n",
    "        return None, None\n",
    "    # å–å€é–“å¯¬åº¦æœ€å°è€…ï¼ˆé¿å…é‡ç–Šæ™‚æ­§ç¾©ï¼‰\n",
    "    best = min(hits, key=lambda r: (r[\"hi\"] - r[\"lo\"], -r[\"Bpm\"]))\n",
    "    Bpm  = best[\"Bpm\"]\n",
    "    B_range = (-Bpm, Bpm)\n",
    "    meta = {\"mVpp\": best[\"mVpp\"], \"fmHz\": best[\"fmHz\"], \"lo\": best[\"lo\"], \"hi\": best[\"hi\"]}\n",
    "    return B_range, meta\n",
    "\n",
    "def _folder_has_scan_csv(folder: Path, root_for_pick: Path) -> bool:\n",
    "    \"\"\"è³‡æ–™å¤¾å…§æ˜¯å¦å­˜åœ¨ä¸€å€‹ã€æƒæ CSVã€å¯è¢« _pick_scan_csv() æŒ‘åˆ°ã€‚\"\"\"\n",
    "    try:\n",
    "        return _pick_scan_csv(folder, root=root_for_pick) is not None\n",
    "    except Exception:\n",
    "        return False\n",
    "def _detect_layout(root_dir: Path):\n",
    "    \"\"\"\n",
    "    ä¾ã€å±¤ç´šã€è‡ªå‹•åˆ¤æ–·è³‡æ–™çµæ§‹ï¼š\n",
    "    - è‹¥ root/ è‡ªå·±å°±æœ‰æƒæ CSV â†’ ('single', [root], 'all_only')\n",
    "    - è‹¥ root/ åº•ä¸‹çš„ç¬¬ä¸€å±¤å­è³‡æ–™å¤¾å°±å„è‡ªæœ‰æƒæ CSV â†’ ('flat', [root], 'all_only')\n",
    "    - è‹¥ root/ åº•ä¸‹ç¬¬ä¸€å±¤æ²’æœ‰ï¼Œä½†å…¶å­å±¤æœ‰æƒæ CSV â†’ ('session', [æ¯å€‹ç¬¬ä¸€å±¤å­è³‡æ–™å¤¾], 'per_session')\n",
    "    - å…¶ä»–æƒ…æ³ â†’ ç•¶æˆ single\n",
    "    \"\"\"\n",
    "    # C. æ ¹ç›®éŒ„è‡ªå·±æ˜¯ä¸€ç­†\n",
    "    if _folder_has_scan_csv(root_dir, root_for_pick=root_dir):\n",
    "        return ('single', [root_dir], 'all_only')\n",
    "\n",
    "    lvl1 = [p for p in sorted(root_dir.iterdir()) if p.is_dir() and p.name != NOISE_SUBDIR]\n",
    "    if not lvl1:\n",
    "        return ('single', [root_dir], 'all_only')\n",
    "\n",
    "    # A. æ‰å¹³ï¼šç¬¬ä¸€å±¤è³‡æ–™å¤¾å„è‡ªå°±æ˜¯æ•¸æ“šè³‡æ–™å¤¾\n",
    "    if any(_folder_has_scan_csv(d, root_for_pick=root_dir) for d in lvl1):\n",
    "        return ('flat', [root_dir], 'all_only')\n",
    "\n",
    "    # B. sessionï¼šç¬¬ä¸€å±¤ä¸æ˜¯æ•¸æ“šï¼Œä½†å…¶ç¬¬äºŒå±¤æ‰æœ‰æ•¸æ“š\n",
    "    session_dirs = []\n",
    "    for s in lvl1:\n",
    "        subdirs = [p for p in sorted(s.iterdir()) if p.is_dir() and p.name != NOISE_SUBDIR]\n",
    "        if any(_folder_has_scan_csv(sd, root_for_pick=s) for sd in subdirs):\n",
    "            session_dirs.append(s)\n",
    "\n",
    "    if session_dirs:\n",
    "        return ('session', session_dirs, 'per_session')\n",
    "\n",
    "    # fallback\n",
    "    return ('single', [root_dir], 'all_only')\n",
    "\n",
    "\n",
    "def _is_summary_name(p: Path, root: Path) -> bool:\n",
    "    \"\"\"æ˜¯å¦ç‚ºä¸»è³‡æ–™å¤¾åŒåçš„å½™æ•´ CSVï¼ˆéœ€è¦é¿é–‹é¿å…èª¤è®€ï¼‰ã€‚\"\"\"\n",
    "    summary_name = f\"{root.name}.csv\"\n",
    "    return (p.name == summary_name)\n",
    "\n",
    "def _pick_scan_csv(folder: Path, root: Path) -> Path | None:\n",
    "    \"\"\"æŒ‘é¸æ¯å€‹æ•¸æ“šè³‡æ–™å¤¾å…§çš„æƒå ´ CSVï¼›è·³é noise/ èˆ‡ä¸»å½™æ•´æª”ï¼ˆroot/<root>.csv æˆ– session/<session>.csvï¼‰ã€‚\"\"\"\n",
    "    cands = []\n",
    "    for csv in folder.glob(SCAN_CSV_GLOB):\n",
    "        if csv.is_dir():\n",
    "            continue\n",
    "        # è·³é noise\n",
    "        if csv.parent.name == NOISE_SUBDIR:\n",
    "            continue\n",
    "        # è·³éã€å’Œ root åŒåã€çš„å½™æ•´ csvï¼ˆé¿å…èª¤è®€ï¼‰\n",
    "        if csv.name == f\"{root.name}.csv\":\n",
    "            continue\n",
    "        cands.append(csv)\n",
    "    return sorted(cands)[0] if cands else None\n",
    "\n",
    "def _pick_noise_csv(noise_dir: Path) -> Path | None:\n",
    "    \"\"\"åœ¨ noise/ å­è³‡æ–™å¤¾æŒ‘ç¬¬ä¸€å€‹ CSVã€‚\"\"\"\n",
    "    if not noise_dir.exists() or not noise_dir.is_dir():\n",
    "        return None\n",
    "    for csv in sorted(noise_dir.glob(\"*.csv\")):\n",
    "        if csv.is_file():\n",
    "            return csv\n",
    "    return None\n",
    "\n",
    "def _standardize_scan_df(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    å…ˆä¾æ¬„ä½é †åºæ“·å–ï¼š\n",
    "      time <- ç¬¬ SCAN_POS_MAP['time'] æ¬„\n",
    "      Ab   <- ç¬¬ SCAN_POS_MAP['Ab']   æ¬„\n",
    "      demod<- ç¬¬ SCAN_POS_MAP['demod']æ¬„\n",
    "      tri  <- ç¬¬ SCAN_POS_MAP['tri']  æ¬„\n",
    "    è‹¥ä½ç½®ä¸è¶³æˆ–å¤±æ•—ï¼Œæ‰é€€å›èˆŠçš„ã€ŒæŒ‰æ¬„åé—œéµå­—ã€æ¨¡å¼ã€‚\n",
    "    æœ€å¾Œä¾ USER_SCAN_COLNAMES é‡æ–°å‘½åè¼¸å‡ºæ¬„åã€‚\n",
    "    \"\"\"\n",
    "    df_raw = df_raw.copy()\n",
    "    out_names = USER_SCAN_COLNAMES\n",
    "\n",
    "    # --- ä½ç½®å„ªå…ˆ ---\n",
    "    if SCAN_USE_POSITION:\n",
    "        try:\n",
    "            cols = {}\n",
    "            for k, idx in SCAN_POS_MAP.items():\n",
    "                if idx >= df_raw.shape[1]:\n",
    "                    raise IndexError(f\"æƒæ CSV æ¬„æ•¸ä¸è¶³ï¼ˆéœ€è¦ç¬¬ {idx} æ¬„ä½œ {k}ï¼‰\")\n",
    "                cols[k] = pd.to_numeric(df_raw.iloc[:, idx], errors=\"coerce\")\n",
    "            df = pd.DataFrame(cols).dropna(how=\"any\")\n",
    "            # é‡æ–°å‘½åç‚ºä½¿ç”¨è€…æŒ‡å®š\n",
    "            df = df.rename(columns={k: out_names.get(k, k) for k in cols})\n",
    "            return df\n",
    "        except Exception:\n",
    "            # å¤±æ•—å°±èµ°åç¨±è¾¨è­˜\n",
    "            pass\n",
    "\n",
    "    # --- åç¨±è¾¨è­˜ï¼ˆfallbackï¼‰ ---\n",
    "    norm = {re.sub(r\"\\s+\", \"\", c.lower()): c for c in df_raw.columns}\n",
    "    def pick(key_part, fallback=None):\n",
    "        for k, orig in norm.items():\n",
    "            if key_part in k:\n",
    "                return orig\n",
    "        return fallback\n",
    "\n",
    "    tcol = pick(\"time\")\n",
    "    Acol = pick(\"channela(\", pick(\"channela\"))\n",
    "    Bcol = pick(\"channelb(\", pick(\"channelb\"))\n",
    "    Ccol = pick(\"channelc(\", pick(\"channelc\"))\n",
    "    if not (tcol and Acol and Bcol and Ccol):\n",
    "        raise ValueError(\"æƒæ CSV ç¼ºå°‘éœ€è¦çš„æ¬„ä½ï¼ˆéœ€å« Timeã€Channel A/B/C æˆ–æä¾›è¶³å¤ æ¬„ä½é †åºï¼‰ã€‚\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        out_names.get(\"time\",\"time\"):  pd.to_numeric(df_raw[tcol], errors=\"coerce\"),\n",
    "        out_names.get(\"Ab\",\"Ab\"):      pd.to_numeric(df_raw[Acol], errors=\"coerce\"),\n",
    "        out_names.get(\"demod\",\"demod\"):pd.to_numeric(df_raw[Bcol], errors=\"coerce\"),\n",
    "        out_names.get(\"tri\",\"tri\"):    pd.to_numeric(df_raw[Ccol], errors=\"coerce\"),\n",
    "    }).dropna(how=\"any\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _standardize_noise_df(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    é›œè¨Šæª”ä¹Ÿå…ˆä¾æ¬„ä½é †åºæ“·å–ï¼ˆé€šå¸¸åªæœ‰å‰ä¸‰æ¬„ï¼‰ï¼š\n",
    "      time <- NOISE_POS_MAP['time']\n",
    "      Ab   <- NOISE_POS_MAP['Ab']     ï¼ˆå¯æœ‰å¯ç„¡ï¼Œä¸ç”¨ä¹Ÿç„¡æ‰€è¬‚ï¼‰\n",
    "      demod<- NOISE_POS_MAP['demod']  â† PSD ç”¨é€™ä¸€æ¬„\n",
    "    è‹¥ä½ç½®å¤±æ•—å†æŒ‰åç¨±è¾¨è­˜ã€‚\n",
    "    æœ€å¾Œè¼¸å‡ºä¸‰æ¬„ï¼štime, sig1, sig2ï¼ˆsig2=demodï¼‰ï¼Œä»¥ç¬¦åˆ noise_psd(_lowband) ä»‹é¢ã€‚\n",
    "    \"\"\"\n",
    "    df_raw = df_raw.copy()\n",
    "    out_names = USER_NOISE_COLNAMES\n",
    "\n",
    "    # --- ä½ç½®å„ªå…ˆ ---\n",
    "    if NOISE_USE_POSITION:\n",
    "        try:\n",
    "            # time\n",
    "            t_idx = NOISE_POS_MAP[\"time\"]\n",
    "            if t_idx >= df_raw.shape[1]:\n",
    "                raise IndexError(\"noise CSV æ¬„æ•¸ä¸è¶³ï¼ˆtimeï¼‰\")\n",
    "            time = pd.to_numeric(df_raw.iloc[:, t_idx], errors=\"coerce\")\n",
    "\n",
    "            # demod\n",
    "            d_idx = NOISE_POS_MAP[\"demod\"]\n",
    "            if d_idx >= df_raw.shape[1]:\n",
    "                raise IndexError(\"noise CSV æ¬„æ•¸ä¸è¶³ï¼ˆdemodï¼‰\")\n",
    "            demod = pd.to_numeric(df_raw.iloc[:, d_idx], errors=\"coerce\")\n",
    "\n",
    "            # Abï¼ˆå¯é¸ï¼‰\n",
    "            a_val = None\n",
    "            if \"Ab\" in NOISE_POS_MAP and NOISE_POS_MAP[\"Ab\"] < df_raw.shape[1]:\n",
    "                a_val = pd.to_numeric(df_raw.iloc[:, NOISE_POS_MAP[\"Ab\"]], errors=\"coerce\")\n",
    "\n",
    "            df = pd.DataFrame({\n",
    "                out_names.get(\"time\",\"time\"): time,\n",
    "                # PSD å‡½å¼éœ€è¦ä¸‰æ¬„ï¼›sig1 å¯æ”¾ 0 æˆ– Abï¼Œä¸å½±éŸ¿æˆ‘å€‘ç”¨ sig2 ç®— PSD\n",
    "                \"sig1\": (a_val if a_val is not None else 0.0),\n",
    "                \"sig2\": demod,\n",
    "            }).dropna(how=\"any\")\n",
    "            return df\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # --- åç¨±è¾¨è­˜ï¼ˆfallbackï¼‰ ---\n",
    "    import re\n",
    "    norm = {re.sub(r\"\\s+\", \"\", c.lower()): c for c in df_raw.columns}\n",
    "    def pick(key_part, fallback=None):\n",
    "        for k, orig in norm.items():\n",
    "            if key_part in k:\n",
    "                return orig\n",
    "        return fallback\n",
    "\n",
    "    tcol = pick(\"time\")\n",
    "    Bcol = pick(\"channelb(\", pick(\"channelb\"))\n",
    "    if not (tcol and Bcol):\n",
    "        raise ValueError(\"noise CSV éœ€è‡³å°‘æœ‰ Time èˆ‡ Channel Bï¼Œæˆ–æä¾›è¶³å¤ æ¬„ä½é †åºã€‚\")\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        out_names.get(\"time\",\"time\"):  pd.to_numeric(df_raw[tcol], errors=\"coerce\"),\n",
    "        \"sig2\":  pd.to_numeric(df_raw[Bcol], errors=\"coerce\"),\n",
    "    }).dropna(how=\"any\")\n",
    "    return df\n",
    "\n",
    "def _read_csv_safely(csv_path: Path) -> pd.DataFrame:\n",
    "    # å¿½ç•¥ä»¥ % é–‹é ­çš„ Moku è¨»è§£ï¼Œsep=None è®“ pandas è‡ªå‹•åˆ¤æ–·é€—é»/Tab/åˆ†è™Ÿ\n",
    "    df = pd.read_csv(\n",
    "        csv_path, engine=\"python\", sep=None, comment=\"%\",\n",
    "        skip_blank_lines=True, encoding=\"utf-8-sig\"\n",
    "    )\n",
    "    df = df.dropna(axis=1, how=\"all\").dropna(axis=0, how=\"all\")\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _choose_xy(df: pd.DataFrame) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    æŒ‘é¸ x, y æ¬„ä½ï¼š\n",
    "    å„ªå…ˆä½¿ç”¨ ('B','demod')ï¼›å…¶æ¬¡ ('B','S')ï¼›å†å…¶æ¬¡ ('Ab','demod')ï¼›\n",
    "    éƒ½æ²’æœ‰å°±æ‰¾æ•¸å€¼æ¬„ï¼Œå‹•æ…‹ç¯„åœå¤§è€…ç•¶ xï¼Œå°è€…ç•¶ yï¼ˆæœ€ä¿å®ˆ fallbackï¼‰ã€‚\n",
    "    \"\"\"\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    # å…ˆæ˜ç¢ºçš„å‘½å\n",
    "    if \"b\" in cols and \"demod\" in cols:\n",
    "        return cols[\"b\"], cols[\"demod\"]\n",
    "    if \"b\" in cols and \"s\" in cols:\n",
    "        return cols[\"b\"], cols[\"s\"]\n",
    "    if \"ab\" in cols and \"demod\" in cols:\n",
    "        # ä½ ä¹‹å‰çš„ dispersive æ˜¯æŠŠ (Ab, demod) è¦–ç‚º (x,y)\n",
    "        return cols[\"ab\"], cols[\"demod\"]\n",
    "\n",
    "    # é€€è€Œæ±‚å…¶æ¬¡ï¼šæ‰¾æ•¸å€¼æ¬„\n",
    "    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if len(num_cols) < 2:\n",
    "        # å…¨éƒ¨æ•¸å€¼åŒ–è©¦è©¦\n",
    "        try:\n",
    "            dfn = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "            num_cols = [c for c in dfn.columns if pd.api.types.is_numeric_dtype(dfn[c])]\n",
    "        except Exception:\n",
    "            pass\n",
    "    if len(num_cols) < 2:\n",
    "        raise ValueError(\"ç„¡æ³•åˆ¤å®š x/y æ¬„ä½ï¼Œè«‹æª¢æŸ¥ CSV æ¬„åæˆ–å…§å®¹ã€‚\")\n",
    "\n",
    "    ranges = sorted(\n",
    "        [(df[c].astype(float).max() - df[c].astype(float).min(), c) for c in num_cols],\n",
    "        reverse=True\n",
    "    )\n",
    "    x_col = ranges[0][1]\n",
    "    # é¿å…åŒæ¬„\n",
    "    y_col = next((c for _, c in ranges[1:] if c != x_col), ranges[1][1])\n",
    "    return x_col, y_col\n",
    "\n",
    "\n",
    "\n",
    "def _compute_noise(noise_df_raw: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    3â€“80 Hz band-mean ASDï¼ˆV/âˆšHzï¼‰ï¼Œèˆ‡å–®ç¨è¨ˆç®—å®Œå…¨å°é½Šï¼š\n",
    "      - lowband è·¯å¾‘ï¼ˆå¯é–‹é—œé è™•ç†ï¼‰\n",
    "      - Hann + median\n",
    "      - å›ºå®š df ~ NOISE_LOCK_DF_HZ\n",
    "      - ä¸åš power-of-2 snap\n",
    "      - detrend ä¾ NOISE_DETREND\n",
    "    \"\"\"\n",
    "    df = _standardize_noise_df(noise_df_raw)\n",
    "\n",
    "    # é–æ­»æ‰€æœ‰æœƒå½±éŸ¿çµæœçš„åƒæ•¸\n",
    "    kwargs_common = dict(\n",
    "        band=NOISE_BAND,\n",
    "        window=NOISE_WINDOW,\n",
    "        average=NOISE_AVERAGE,\n",
    "        min_freq_resolution=NOISE_LOCK_DF_HZ, # ç›´æ¥é–å®š df\n",
    "        force_long_segments=False,             # ä¸ç‚ºäº† df çŠ§ç‰²æ®µæ•¸ï¼ˆè·Ÿå–®ç¨ç®—ä¸€è‡´å°±å¥½ï¼‰\n",
    "        detrend=NOISE_DETREND,\n",
    "        snap_to_power_of_2=False               # ä¸èª¿æ•´åˆ° 2 çš„æ¬¡æ–¹ï¼Œé¿å… df æ¼‚ç§»\n",
    "    )\n",
    "\n",
    "    if NOISE_MODE == \"lowband\":\n",
    "        _, mean_rms, _, info = noise_psd_lowband(\n",
    "            df,\n",
    "            enable_auto_preprocess=NOISE_ENABLE_PREPROCESS,\n",
    "            # å…¶é¤˜é è™•ç†åƒæ•¸æ¡ç”¨å‡½å¼é è¨­ï¼ˆlowband_hi=150, oversample=5, fs_floor=250, fs_ceil=800, lp_margin=0.30ï¼‰\n",
    "            **kwargs_common\n",
    "        )\n",
    "    else:\n",
    "        _, mean_rms, _, info = noise_psd(\n",
    "            df,\n",
    "            **kwargs_common\n",
    "        )\n",
    "\n",
    "    # ï¼ˆå¯é¸ï¼‰åœ¨é™¤éŒ¯æ™‚å°å‡ºï¼Œç¢ºèªå¯¦éš› band èˆ‡ df æ˜¯å¦å¦‚é æœŸ\n",
    "    # print({\"band_range\": info.get(\"band_range\"), \"df\": info.get(\"df\"),\n",
    "    #        \"n_segments\": info.get(\"n_segments\"), \"preprocessed\": info.get(\"preprocessed\")})\n",
    "\n",
    "    return float(mean_rms)  # V/âˆšHz\n",
    "\n",
    "_session_re = re.compile(SESSION_NAME_PATTERN)\n",
    "def _looks_like_session_name(name: str) -> bool:\n",
    "    \"\"\"åƒ 01/02/03 æˆ– 01_xx/02-yy å°±ç•¶ä½œ sessionã€‚\"\"\"\n",
    "    return bool(re.match(r\"^\\d{2,}([ _-].*)?$\", name))\n",
    "\n",
    "def _progress_printer(total: int, step: int = 10):\n",
    "    \"\"\"\n",
    "    ROOT å±¤é€²åº¦ï¼ˆ10%/20%â€¦ï¼‰ï¼ŒåŒæ™‚é¡¯ç¤º å·²å®Œæˆ/ç¸½æ•¸ã€‚\n",
    "    ç”¨æ³•ï¼šupd(k, prefix='[ROOT] ')ï¼›k å¾ 1..total\n",
    "    \"\"\"\n",
    "    fired = set()\n",
    "    def upd(done: int, prefix: str = \"\"):\n",
    "        if total <= 0:\n",
    "            return\n",
    "        pct = int(done * 100 / total)\n",
    "        bucket = (pct // step) * step\n",
    "        if bucket not in fired and pct >= step:\n",
    "            fired.add(bucket)\n",
    "            print(f\"{prefix}{pct}%  ({done}/{total})\")\n",
    "    return upd\n",
    "\n",
    "def _write_outputs(root_dir: Path, sheets: dict[str, pd.DataFrame], sheet_mode: str = \"per_session\"):\n",
    "    if not sheets:\n",
    "        print(\"[WARN] æ²’æœ‰å¯è¼¸å‡ºçš„è³‡æ–™ã€‚\")\n",
    "        return\n",
    "\n",
    "    df_all = pd.concat(sheets.values(), ignore_index=True)\n",
    "\n",
    "    # åœ¨çµ‚ç«¯æ©Ÿåˆ—å° ALLï¼Œé¿å…ä½ é‚„è¦é–‹æª”\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ALL (å½™æ•´ç¸½è¡¨)\".center(80))\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # æ›´æ¸…æ¥šçš„é¡¯ç¤ºè¨­å®š\n",
    "        with pd.option_context(\n",
    "            \"display.max_rows\", None,\n",
    "            \"display.max_columns\", None, \n",
    "            \"display.width\", 200,           # åŠ å¯¬\n",
    "            \"display.max_colwidth\", 15,     # é™åˆ¶å–®æ¬„å¯¬åº¦\n",
    "            \"display.precision\", 3,         # æ•¸å­—ç²¾åº¦\n",
    "            \"display.float_format\", '{:.3g}'.format,  # ç§‘å­¸è¨˜è™Ÿæ ¼å¼\n",
    "            \"display.colheader_justify\", \"center\"     # è¡¨é ­ç½®ä¸­\n",
    "        ):\n",
    "            # ä½¿ç”¨ tabulate é¢¨æ ¼çš„è¡¨æ ¼ï¼ˆå¦‚æœæ¬„ä½å¤ªå¤šå¯ä»¥åˆ†æ®µé¡¯ç¤ºï¼‰\n",
    "            if len(df_all.columns) > 10:\n",
    "                # åˆ†æ®µé¡¯ç¤ºï¼šåŸºæœ¬è³‡è¨Š + å„é¡æŒ‡æ¨™\n",
    "                basic_cols = [col for col in df_all.columns if any(x in col.lower() \n",
    "                             for x in ['label', 'folder', 'current', 'power', 'range'])]\n",
    "                metric_cols = [col for col in df_all.columns if col not in basic_cols]\n",
    "                \n",
    "                print(\"\\nğŸ“‹ åŸºæœ¬è³‡è¨Šï¼š\")\n",
    "                print(df_all[basic_cols].to_string(index=False))\n",
    "                \n",
    "                print(f\"\\nğŸ“Š æ¸¬é‡çµæœï¼š\")\n",
    "                print(df_all[metric_cols].to_string(index=False))\n",
    "            else:\n",
    "                print(df_all.to_string(index=False))\n",
    "                \n",
    "        print(\"=\"*80)\n",
    "        print(f\"å…± {len(df_all)} ç­†è³‡æ–™\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] çµ‚ç«¯åˆ—å°å¤±æ•—ï¼š{e}\")\n",
    "\n",
    "    # CSVï¼ˆALLï¼‰\n",
    "    csv_path = root_dir / f\"{root_dir.name}.csv\"\n",
    "    df_all.to_csv(csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"[OK] å·²è¼¸å‡º CSVï¼š{csv_path}\")\n",
    "\n",
    "    # XLSX\n",
    "    xlsx_path = root_dir / f\"{root_dir.name}.xlsx\"\n",
    "    with pd.ExcelWriter(xlsx_path, engine=\"openpyxl\") as xw:\n",
    "        if sheet_mode == \"all_only\":\n",
    "            df_all.to_excel(xw, sheet_name=\"ALL\", index=False)\n",
    "        else:\n",
    "            for name, df in sheets.items():\n",
    "                sheet = re.sub(r'[\\\\/*?:\\[\\]]', '_', name)[:31] or \"Sheet\"\n",
    "                df.to_excel(xw, sheet_name=sheet, index=False)\n",
    "            if len(sheets) > 1:\n",
    "                df_all.to_excel(xw, sheet_name=\"ALL\", index=False)\n",
    "\n",
    "    print(f\"[OK] å·²è¼¸å‡º XLSXï¼š{xlsx_path}\")\n",
    "    \n",
    "\n",
    "\n",
    "def _extract_current_from_label(label: str, offset=0.0) -> float | None:\n",
    "    m = re.search(r\"([-+]?\\d+(?:\\.\\d+)?)\", label)\n",
    "    return (float(m.group(1)) + offset) if m else None\n",
    "\n",
    "def process_session(session_dir: Path, rules_from_txt: list, root_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    # é€™å€‹ session åº•ä¸‹çš„å¯¦é©—è³‡æ–™å¤¾ï¼ˆæ’é™¤ noise/ï¼‰\n",
    "    subdirs = [p for p in sorted(session_dir.iterdir())\n",
    "               if p.is_dir() and p.name != NOISE_SUBDIR]\n",
    "\n",
    "    # âœ… è‹¥æ²’æœ‰ä»»ä½•å­è³‡æ–™å¤¾ï¼Œå°±ç›´æ¥æŠŠ session_dir è‡ªå·±ç•¶æˆä¸€ç­†å¯¦é©—\n",
    "    if not subdirs:\n",
    "        subdirs = [session_dir]\n",
    "\n",
    "    # é€²åº¦æ¢ï¼ˆ10%ã€20%â€¦ï¼‰\n",
    "    upd = _progress_printer(len(subdirs))\n",
    "\n",
    "    for j, sub in enumerate(subdirs, start=1):\n",
    "        tag = session_dir.name if session_dir != root_dir else \"SINGLE\"\n",
    "        upd(j, prefix=f\"[{tag}] \")\n",
    "\n",
    "        # è§£ææƒå ´ç¯„åœ\n",
    "        B_range_used, _meta = _choose_rule_for_label(rules_from_txt, sub.name)\n",
    "        if not B_range_used:\n",
    "            B_range_used = B_RANGE_NT\n",
    "\n",
    "        # æ³¨æ„ï¼šåƒæ•¸åæ˜¯ root\n",
    "        scan_csv = _pick_scan_csv(sub, root=session_dir)\n",
    "        if scan_csv is None:\n",
    "            continue\n",
    "\n",
    "        # è®€æƒææª”\n",
    "        try:\n",
    "            df_raw = _read_csv_safely(scan_csv)\n",
    "            df_scan = _standardize_scan_df(df_raw)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {session_dir.name}/{sub.name}: æƒææª”è§£æå¤±æ•—ï¼š{e}\")\n",
    "            continue\n",
    "\n",
    "        # åˆ‡ä¸€æ®µæƒå ´ä¸¦æ˜ å°„ B\n",
    "        try:\n",
    "            BField, AbCut, DemodCut = one_cycle_cut(\n",
    "                df_scan.rename(columns={\"tri\":\"tri\"}),\n",
    "                B_range=B_range_used,\n",
    "                segment=LINE_SEGMENT,\n",
    "                direction=LINE_DIRECTION,\n",
    "                time_col=\"time\", ab_col=\"Ab\", demod_col=\"demod\", tri_col=\"tri\",\n",
    "                map_mode='global', smooth_win=5\n",
    "            )\n",
    "            df_bs = pd.DataFrame({\"B\": BField, \"Ab\": AbCut, \"demod\": DemodCut})\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {session_dir.name}/{sub.name}: one_cycle_cut å¤±æ•—ï¼š{e}\")\n",
    "            df_bs = pd.DataFrame({\"Ab\": df_scan[\"Ab\"], \"demod\": df_scan[\"demod\"]})\n",
    "\n",
    "        # éœ€æ±‚åˆ¤æ–·\n",
    "        need_slope = _want(\"slope\") or _want(\"sloper2\") or _want(\"sensitivity\")\n",
    "        need_noise = _want(\"noisepsd\") or _want(\"sensitivity\")\n",
    "        need_voigt = any(_want(k) for k in (\"voigtfwhm\",\"voigtgamma\",\"voigtsigma\",\"voigtR2\"))\n",
    "        need_lor   = any(_want(k) for k in (\"lorentzfwhm\",\"lorentzR2\"))\n",
    "        need_gau   = any(_want(k) for k in (\"gaussianfwhm\",\"gaussianR2\"))\n",
    "\n",
    "        # ---- slopeï¼ˆdispersionï¼šå›ºå®šä¸­å¿ƒ + å›ºå®šçª—ï¼‰----\n",
    "        slope_val = np.nan   # V/nT\n",
    "        slope_R2  = np.nan\n",
    "        disp = None\n",
    "        if need_slope:\n",
    "            try:\n",
    "                if \"B\" in df_bs.columns:\n",
    "                    # åªç”¨èšç„¦çª—è³‡æ–™\n",
    "                    B_all = df_bs[\"B\"].to_numpy(float)\n",
    "                    Y_all = df_bs[\"demod\"].to_numpy(float)\n",
    "        \n",
    "                    Bspan = float(B_all.max() - B_all.min())\n",
    "                    half  = max(1e-9, Bspan * (WIDTHRATIO/100.0))\n",
    "                    m = (B_all >= (DISP_CENTER - half)) & (B_all <= (DISP_CENTER + half))\n",
    "                    # é»æ•¸ä¸è¶³å°±é€æ­¥æ”¾å¯¬\n",
    "                    if m.sum() < 12:\n",
    "                        for s in (1.5, 2.0, 3.0):\n",
    "                            mm = (B_all >= (DISP_CENTER - half*s)) & (B_all <= (DISP_CENTER + half*s))\n",
    "                            if mm.sum() >= 12:\n",
    "                                m = mm; break\n",
    "                        else:\n",
    "                            m = np.ones_like(B_all, dtype=bool)\n",
    "        \n",
    "                    Bf, Yf = B_all[m], Y_all[m]\n",
    "                    df_focus = pd.DataFrame({\"x\": Bf, \"y\": Yf})\n",
    "        \n",
    "                    # è·Ÿå–®ç¨ç®—ä¸€è‡´ï¼šå›ºå®šä¸­å¿ƒ + amplitude 0.01V\n",
    "                    disp = dispersion_lorentz_fit(\n",
    "                        df_focus,\n",
    "                        p0={'center': DISP_CENTER, 'amplitude': DISP_P0_AMPL},\n",
    "                        max_rel_err=0.01\n",
    "                    )\n",
    "        \n",
    "                    slope_val = float(disp[\"Slope\"])   # a*b  (V/nT)\n",
    "                    slope_R2  = float(disp[\"R2\"])\n",
    "        \n",
    "                    # --- ç¹ªåœ–ï¼ˆèšç„¦çª—è³‡æ–™ + æ“¬åˆ + ç·šæ€§ç¯„åœ/è¿‘ä¼¼ï¼‰---\n",
    "                    if PLOT_ENABLED and np.isfinite(slope_val):\n",
    "                        try:\n",
    "                            lin_lo, lin_hi = disp.get(\"LinearRange\", (None, None))\n",
    "                            ctr   = disp[\"Params\"][\"center\"]\n",
    "                            c0    = disp[\"Params\"][\"offset\"]\n",
    "                            yfit  = disp[\"Data\"][\"S_fit\"]  # èˆ‡èšç„¦çª—åŒé•·åº¦\n",
    "                            _plot_and_save_dispersion(\n",
    "                                sub_dir=sub,\n",
    "                                B=Bf, demod=Yf, yfit=yfit,\n",
    "                                slope=slope_val, r2=slope_R2,\n",
    "                                lin_range=(lin_lo, lin_hi),\n",
    "                                ctr=ctr, offset=c0\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            print(f\"[WARN] slope ç¹ªåœ–å‘¼å«å¤±æ•—ï¼š{sub.name}: {e}\")\n",
    "        \n",
    "                else:\n",
    "                    # æ²’ B è»¸å°±é€€å› (Ab, demod)ï¼Œä½†é€™ç¨®æƒ…æ³é€šå¸¸ä¸å»ºè­°ç®— slope\n",
    "                    df_disp = df_bs.rename(columns={\"Ab\": \"x\", \"demod\": \"y\"})[[\"x\", \"y\"]].dropna()\n",
    "                    disp = dispersion_lorentz_fit(df_disp, p0={'center': 0.0, 'amplitude': DISP_P0_AMPL}, max_rel_err=0.01)\n",
    "                    slope_val = float(disp[\"Slope\"])\n",
    "                    slope_R2  = float(disp[\"R2\"])\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] {sub.name}: dispersion æ“¬åˆå¤±æ•—ï¼š{e}\")\n",
    "\n",
    "        # ---- ç·šå‹ï¼ˆLorentz / Gaussian / Voigtï¼‰----\n",
    "        lorentz_FWHM = gaussian_FWHM = voigt_FWHM = np.nan\n",
    "        lorentz_R2 = gaussian_R2 = vR2 = np.nan\n",
    "        v_sigma = v_gamma = np.nan\n",
    "\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=r\"Using UFloat objects with std_dev==0.*\",\n",
    "            category=UserWarning,\n",
    "            module=r\"uncertainties\\.core\"\n",
    "        )\n",
    "\n",
    "        lf = gf = vf = None\n",
    "        if \"B\" in df_bs.columns:\n",
    "            if need_lor:\n",
    "                try:\n",
    "                    lf = lorentz_fit(df_bs[[\"B\",\"Ab\"]])\n",
    "                    lorentz_FWHM = float(lf[\"FWHM\"]) if \"FWHM\" in lf else 2.0*abs(float(lf[\"gamma\"]))\n",
    "                    lorentz_R2   = _first_scalar(lf.get(\"R2\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] {sub.name}: Lorentz æ“¬åˆå¤±æ•—ï¼š{e}\")\n",
    "\n",
    "            if need_gau:\n",
    "                try:\n",
    "                    gf = gauss_fit(df_bs[[\"B\",\"Ab\"]])\n",
    "                    gaussian_FWHM = float(gf[\"FWHM\"]) if \"FWHM\" in gf else 2.0*np.sqrt(2.0*np.log(2.0))*abs(float(gf[\"sigma\"]))\n",
    "                    gaussian_R2   = _first_scalar(gf.get(\"R2\"))\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] {sub.name}: Gaussian æ“¬åˆå¤±æ•—ï¼š{e}\")\n",
    "\n",
    "            if need_voigt:\n",
    "                try:\n",
    "                    vf      = voigt_fit(df_bs[[\"B\",\"Ab\"]])\n",
    "                    v_sigma = float(vf.get(\"sigma\", np.nan))\n",
    "                    v_gamma = float(vf.get(\"gamma\", np.nan))\n",
    "                    vR2     = _first_scalar(vf.get(\"R2\"))\n",
    "                    L = 2.0*abs(v_gamma)\n",
    "                    G = 2.0*np.sqrt(2.0*np.log(2.0))*abs(v_sigma)\n",
    "                    voigt_FWHM = 0.5346*L + np.sqrt(0.2166*L*L + G*G)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] {sub.name}: Voigt æ“¬åˆå¤±æ•—ï¼š{e}\")\n",
    "\n",
    "            # ä½œåœ–ï¼ˆlineshape ç–Šåœ–ï¼‰\n",
    "            if PLOT_ENABLED and (need_lor or need_gau or need_voigt):\n",
    "                _plot_and_save_lineshapes(\n",
    "                    sub_dir=sub,\n",
    "                    B=df_bs[\"B\"].to_numpy(),\n",
    "                    Ab=df_bs[\"Ab\"].to_numpy(),\n",
    "                    want_lor=need_lor, lf=(lf if need_lor else None),\n",
    "                    want_gau=need_gau, gf=(gf if need_gau else None),\n",
    "                    want_voi=need_voigt, vf=(vf if need_voigt else None)\n",
    "                )\n",
    "\n",
    "        # ---- é›œè¨Š / PSD ----\n",
    "        noise_rms = np.nan\n",
    "        if need_noise:\n",
    "            # ç”¨åŒä¸€å¥—æŒ‘æª”é‚è¼¯ï¼šchain ç‰ˆæœ¬ï¼ˆè‹¥ä½ æœ‰å¯«ï¼‰ï¼›å¦å‰‡ç›´æ¥ç”¨è³‡æ–™å¤¾å…§ noise/\n",
    "            try:\n",
    "                noise_csv = _pick_noise_csv_chain(sub, session_dir, root_dir)\n",
    "            except NameError:\n",
    "                noise_csv = _pick_noise_csv(sub / NOISE_SUBDIR)\n",
    "\n",
    "            if noise_csv is not None:\n",
    "                try:\n",
    "                    # ç®—å‡å€¼\n",
    "                    noise_rms = _compute_noise(_read_csv_safely(noise_csv))\n",
    "                    # ç•« PSD\n",
    "                    if PLOT_ENABLED:\n",
    "                        noise_df_raw = _read_csv_safely(noise_csv)\n",
    "                        noise_df_std = _standardize_noise_df(noise_df_raw)\n",
    "                        _plot_and_save_psd(noise_dir=sub/NOISE_SUBDIR, noise_df_std=noise_df_std)\n",
    "                except Exception as e:\n",
    "                    print(f\"[WARN] {session_dir.name}/{sub.name}: å™ªè²è¨ˆç®—æˆ–ç¹ªåœ–å¤±æ•—ï¼š{e}\")\n",
    "\n",
    "        # ---- éˆæ•åº¦ï¼ˆT/âˆšHzï¼‰----\n",
    "        sensitivity = np.nan\n",
    "        if _want(\"sensitivity\") and np.isfinite(noise_rms) and np.isfinite(slope_val) and slope_val != 0:\n",
    "            sensitivity = noise_rms / abs(slope_val)\n",
    "\n",
    "        # === è¼¸å‡ºè¡Œ ===\n",
    "        row = {\n",
    "            \"label\": sub.name,\n",
    "            \"folder_name\": str(sub),\n",
    "            SWEEP_COL_NAME: _extract_sweep_value(sub.name),  # ç”±ä½ çš„æ¨¡å¼å‡½å¼æ±ºå®šï¼šã€Œå…‰å¼·é›»å£“ã€æˆ–ã€Œé›·å°„é›»æµã€\n",
    "            \"B_range_used_nT\": f\"[{B_range_used[0]:.2f}, {B_range_used[1]:.2f}]\",\n",
    "        }\n",
    "        if _want(\"slope\"):        row[_METRIC_COLNAMES[\"slope\"]]       = slope_val * 1e3\n",
    "        if _want(\"sloper2\"):      row[_METRIC_COLNAMES[\"sloper2\"]]     = slope_R2\n",
    "        if _want(\"noisepsd\"):     row[_METRIC_COLNAMES[\"noisepsd\"]]    = noise_rms * 1e6\n",
    "        if _want(\"sensitivity\"):  row[_METRIC_COLNAMES[\"sensitivity\"]] = sensitivity * 1e3  #  pT/âˆšHz\n",
    "        if _want(\"lorentzfwhm\"):  row[_METRIC_COLNAMES[\"lorentzfwhm\"]] = lorentz_FWHM\n",
    "        if _want(\"lorentzr2\"):    row[_METRIC_COLNAMES[\"lorentzr2\"]]   = lorentz_R2\n",
    "        if _want(\"gaussianfwhm\"): row[_METRIC_COLNAMES[\"gaussianfwhm\"]]= gaussian_FWHM\n",
    "        if _want(\"gaussianr2\"):   row[_METRIC_COLNAMES[\"gaussianr2\"]]  = gaussian_R2\n",
    "        if _want(\"voigtfwhm\"):    row[_METRIC_COLNAMES[\"voigtfwhm\"]]   = voigt_FWHM\n",
    "        if _want(\"voigtgamma\"):   row[_METRIC_COLNAMES[\"voigtgamma\"]]  = v_gamma\n",
    "        if _want(\"voigtsigma\"):   row[_METRIC_COLNAMES[\"voigtsigma\"]]  = v_sigma\n",
    "        if _want(\"voigtr2\"):      row[_METRIC_COLNAMES[\"voigtr2\"]]     = vR2\n",
    "        rows.append(row)\n",
    "\n",
    "    dynamic_cols = ALWAYS_COLUMNS + [_METRIC_COLNAMES[k] for k in _METRIC_COLNAMES if k in _SELECT]\n",
    "    return pd.DataFrame(rows, columns=dynamic_cols)\n",
    "   \n",
    "def process_root(root_dir: Path) -> pd.DataFrame:\n",
    "    root_dir = root_dir.resolve()\n",
    "\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\",\n",
    "        message=r\"Using UFloat objects with std_dev==0.*\",\n",
    "        category=UserWarning,\n",
    "        module=r\"uncertainties\\.core\"\n",
    "    )\n",
    "\n",
    "    rules_from_txt = _load_experiment_rules(root_dir)\n",
    "\n",
    "    # â˜… ç”±å±¤ç´šè‡ªå‹•åˆ¤å®š\n",
    "    layout, sessions, sheet_mode = _detect_layout(root_dir)\n",
    "\n",
    "    total = len(sessions)\n",
    "    upd_root = _progress_printer(total)\n",
    "    sheets: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    for i, sess in enumerate(sessions, start=1):\n",
    "        tag = (sess.name if sess != root_dir else root_dir.name)\n",
    "        print(f\"[ROOT] é–‹å§‹è™•ç†ï¼š{tag}  ({i-1}/{total})\")\n",
    "        df_sess = process_session(sess, rules_from_txt, root_dir)\n",
    "        if len(df_sess):\n",
    "            sheets[tag] = df_sess\n",
    "        print(f\"[ROOT] å®Œæˆï¼š{tag}       ({i}/{total})\")\n",
    "        upd_root(i, prefix=\"[ROOT] \")\n",
    "\n",
    "    _write_outputs(root_dir, sheets, sheet_mode=sheet_mode)\n",
    "\n",
    "    return (pd.concat(sheets.values(), ignore_index=True) if sheets else pd.DataFrame())\n",
    "\n",
    "\n",
    "root = Path(r\"C:\\Users\\YiHsuanChen\\OneDrive\\æ¡Œé¢\\Research\\code\\OPM_code\\250925\\å›ºå®šå…‰å¼·æ”¹æ³¢é•·\")\n",
    "process_root(root)\n",
    "notify_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7571abf-9e4a-46b7-a048-a248b6c9d24b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
